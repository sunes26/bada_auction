# ğŸš€ ë°°í¬ ì‹¤í–‰ ê°€ì´ë“œ - ë‹¨ê³„ë³„ ìˆœì„œ

> **ì§€ê¸ˆ ë‹¹ì¥ ë¬´ì—‡ë¶€í„° í•´ì•¼ í•˜ëŠ”ì§€** ëª…í™•í•œ ìˆœì„œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.

---

## ğŸ“‹ ì‹œì‘í•˜ê¸° ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

ë°°í¬ë¥¼ ì‹œì‘í•˜ê¸° ì „ì— í˜„ì¬ ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

```bash
# 1. Backend ì„œë²„ ì‹¤í–‰ í™•ì¸
cd backend
python main.py

# 2. Frontend ì„œë²„ ì‹¤í–‰ í™•ì¸
npm run dev

# 3. ì£¼ìš” ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
- [ ] ìƒí’ˆ ëª¨ë‹ˆí„°ë§ ë™ì‘
- [ ] AI ìƒì„¸í˜ì´ì§€ ìƒì„±
- [ ] í”Œë ˆì´ì˜¤í†  ì£¼ë¬¸ ë™ê¸°í™”
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì •ìƒ ì‘ë™
```

**ëª¨ë“  ê¸°ëŠ¥ì´ ì •ìƒì´ë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”.**

---

## ğŸ¯ ì „ì²´ íƒ€ì„ë¼ì¸ (5-7ì£¼)

```
Week 1-2: Phase 1 - ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
Week 3-4: Phase 2 - ë°±ì—”ë“œ ë°°í¬
Week 5: Phase 3 - í”„ë¡ íŠ¸ì—”ë“œ ë°°í¬
Week 6: Phase 4 - í†µí•© í…ŒìŠ¤íŠ¸
Week 7+: Phase 5 - ìµœì í™” (ì§€ì†)
```

---

## ğŸ“… Week 0: ì‚¬ì „ ì¤€ë¹„ (1-2ì¼)

### Step 0.1: í•„ìˆ˜ ê³„ì • ìƒì„±

ë‹¤ìŒ ì„œë¹„ìŠ¤ì— ê°€ì…í•˜ì„¸ìš” (ëª¨ë‘ ë¬´ë£Œ í‹°ì–´ ê°€ëŠ¥):

#### 1. Supabase (ë°ì´í„°ë² ì´ìŠ¤ & ìŠ¤í† ë¦¬ì§€)
- ğŸ”— https://supabase.com/
- [ ] ê³„ì • ìƒì„± (GitHub ë¡œê·¸ì¸ ì¶”ì²œ)
- [ ] ì´ë©”ì¼ ì¸ì¦
- [ ] í”„ë¡œì íŠ¸ ìƒì„±: "onbaek-ai-production"
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ë¹„ë°€ë²ˆí˜¸ ì„¤ì • (ì•ˆì „í•œ ê³³ì— ì €ì¥!)

**ë°›ì•„ì•¼ í•  ì •ë³´**:
```
SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
DATABASE_URL=postgresql://postgres:[YOUR-PASSWORD]@db.xxxxx.supabase.co:5432/postgres
```

#### 2. Railway (ë°±ì—”ë“œ í˜¸ìŠ¤íŒ…)
- ğŸ”— https://railway.app/
- [ ] ê³„ì • ìƒì„± (GitHub ë¡œê·¸ì¸ ì¶”ì²œ)
- [ ] GitHub ì €ì¥ì†Œ ì—°ë™ ê¶Œí•œ ë¶€ì—¬
- [ ] $5 ë¬´ë£Œ í¬ë ˆë”§ í™•ì¸

#### 3. Vercel (í”„ë¡ íŠ¸ì—”ë“œ í˜¸ìŠ¤íŒ…)
- ğŸ”— https://vercel.com/
- [ ] ê³„ì • ìƒì„± (GitHub ë¡œê·¸ì¸ ì¶”ì²œ)
- [ ] GitHub ì €ì¥ì†Œ ì—°ë™ ê¶Œí•œ ë¶€ì—¬

#### 4. Sentry (ì—ëŸ¬ ëª¨ë‹ˆí„°ë§) - ì„ íƒ
- ğŸ”— https://sentry.io/
- [ ] ê³„ì • ìƒì„±
- [ ] í”„ë¡œì íŠ¸ ìƒì„±: "onbaek-ai-backend"

#### 5. GitHub ì €ì¥ì†Œ í™•ì¸
- [ ] í˜„ì¬ í”„ë¡œì íŠ¸ê°€ GitHubì— í‘¸ì‹œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
- [ ] Private ì €ì¥ì†Œ ê¶Œì¥ (í™˜ê²½ ë³€ìˆ˜ ë³´ì•ˆ)

---

### Step 0.2: ë¡œì»¬ ë°±ì—…

**ì¤‘ìš”**: ë°°í¬ ì „ í˜„ì¬ ë°ì´í„°ë¥¼ ë°±ì—…í•˜ì„¸ìš”!

```bash
# 1. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
cd backend
cp monitoring.db monitoring.db.backup.$(date +%Y%m%d)

# 2. ì´ë¯¸ì§€ í´ë” ë°±ì—…
cd ..
zip -r supabase-images-backup-$(date +%Y%m%d).zip supabase-images/

# 3. .env.local ë°±ì—… (ì•ˆì „í•œ ê³³ì— ë³´ê´€)
cp .env.local .env.local.backup
```

**ë°±ì—… íŒŒì¼ ìœ„ì¹˜ í™•ì¸**:
```
backend/monitoring.db.backup.20260130
supabase-images-backup-20260130.zip
.env.local.backup
```

---

### Step 0.3: Git ë¸Œëœì¹˜ ìƒì„±

ë°°í¬ ì‘ì—…ì„ ë³„ë„ ë¸Œëœì¹˜ì—ì„œ ì§„í–‰í•˜ì„¸ìš”:

```bash
# í˜„ì¬ main ë¸Œëœì¹˜ì—ì„œ ì‘ì—… ì¤‘ì´ë¼ê³  ê°€ì •
git checkout -b deployment-preparation

# ë³€ê²½ì‚¬í•­ ì»¤ë°‹
git add .
git commit -m "Prepare for cloud deployment"
git push -u origin deployment-preparation
```

---

## ğŸ“… Week 1-2: Phase 1 - ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜

### Day 1-2: Supabase ì„¤ì •

#### Step 1.1: Supabase Storage ë²„í‚· ìƒì„±

1. Supabase ëŒ€ì‹œë³´ë“œ â†’ Storage ë©”ë‰´
2. ìƒˆ ë²„í‚· ìƒì„±:

```
ë²„í‚· ì´ë¦„: product-images
Public: âœ… (ì²´í¬)
File size limit: 50MB
Allowed MIME types: image/*
```

3. ë‘ ë²ˆì§¸ ë²„í‚· ìƒì„±:

```
ë²„í‚· ì´ë¦„: detail-pages
Public: âœ… (ì²´í¬)
```

**í™•ì¸**: Storage â†’ product-images, detail-pages ë²„í‚· ìƒì„±ë¨

---

#### Step 1.2: PostgreSQL ìŠ¤í‚¤ë§ˆ ìƒì„±

1. Supabase ëŒ€ì‹œë³´ë“œ â†’ SQL Editor
2. ìƒˆ ì¿¼ë¦¬ ìƒì„±
3. ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:

```sql
-- ê¸°ì¡´ schema.sqlì˜ PostgreSQL ë²„ì „
-- SQLite ì „ìš© ë¬¸ë²•ì„ PostgreSQLë¡œ ë³€í™˜ í•„ìš”

-- ì˜ˆì‹œ: monitored_products í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS monitored_products (
    id SERIAL PRIMARY KEY,
    product_name TEXT NOT NULL,
    product_url TEXT NOT NULL UNIQUE,
    source TEXT NOT NULL,
    current_price REAL,
    original_price REAL,
    current_status TEXT DEFAULT 'available',
    check_interval INTEGER DEFAULT 900,
    last_checked TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    notes TEXT,
    is_active BOOLEAN DEFAULT TRUE,
    thumbnail_url TEXT
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX IF NOT EXISTS idx_monitored_products_source ON monitored_products(source);
CREATE INDEX IF NOT EXISTS idx_monitored_products_status ON monitored_products(current_status);
CREATE INDEX IF NOT EXISTS idx_monitored_products_active ON monitored_products(is_active);

-- ... (ë‚˜ë¨¸ì§€ í…Œì´ë¸”ë„ ë™ì¼í•˜ê²Œ ë³€í™˜)
```

**ì‘ì—… í•„ìš”**:
```bash
# PostgreSQL ìŠ¤í‚¤ë§ˆ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cd backend
python create_postgres_schema.py
```

**ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤** (ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ìƒì„±)

---

#### Step 1.3: SQLite â†’ PostgreSQL ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

**íŒŒì¼ ìƒì„±**: `backend/create_postgres_schema.py`

```python
"""
SQLite schema.sqlì„ PostgreSQLë¡œ ë³€í™˜
"""

def convert_sqlite_to_postgres():
    """SQLite DDLì„ PostgreSQL DDLë¡œ ë³€í™˜"""

    replacements = [
        # INTEGER PRIMARY KEY AUTOINCREMENT â†’ SERIAL PRIMARY KEY
        ('INTEGER PRIMARY KEY AUTOINCREMENT', 'SERIAL PRIMARY KEY'),

        # DATETIME â†’ TIMESTAMP
        ('DATETIME DEFAULT CURRENT_TIMESTAMP', 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP'),
        ('DATETIME', 'TIMESTAMP'),

        # BOOLEAN ì²˜ë¦¬ (SQLiteëŠ” INTEGERë¡œ ì €ì¥)
        ('BOOLEAN DEFAULT 1', 'BOOLEAN DEFAULT TRUE'),
        ('BOOLEAN DEFAULT 0', 'BOOLEAN DEFAULT FALSE'),

        # REAL â†’ DECIMAL ë˜ëŠ” NUMERIC (ë” ì •í™•í•œ ì†Œìˆ˜ì )
        ('REAL', 'NUMERIC(10,2)'),
    ]

    with open('database/schema.sql', 'r', encoding='utf-8') as f:
        sqlite_sql = f.read()

    postgres_sql = sqlite_sql
    for old, new in replacements:
        postgres_sql = postgres_sql.replace(old, new)

    # PostgreSQL ì „ìš© ë¬¸ë²• ì¶”ê°€
    postgres_sql = postgres_sql.replace(
        'CREATE TABLE IF NOT EXISTS',
        'CREATE TABLE IF NOT EXISTS'
    )

    # ì €ì¥
    with open('database/schema_postgres.sql', 'w', encoding='utf-8') as f:
        f.write(postgres_sql)

    print("âœ… PostgreSQL ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ: database/schema_postgres.sql")
    print("ğŸ‘‰ ì´ íŒŒì¼ì„ Supabase SQL Editorì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”")

if __name__ == "__main__":
    convert_sqlite_to_postgres()
```

**ì‹¤í–‰**:
```bash
cd backend
python create_postgres_schema.py
```

**ê²°ê³¼**:
- `backend/database/schema_postgres.sql` íŒŒì¼ ìƒì„±ë¨
- ì´ íŒŒì¼ì„ ë³µì‚¬í•˜ì—¬ Supabase SQL Editorì— ë¶™ì—¬ë„£ê³  ì‹¤í–‰

---

### Day 3-4: SQLAlchemy ORM ì „í™˜

#### Step 1.4: í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
cd backend
pip install sqlalchemy psycopg2-binary alembic python-dotenv
pip freeze > requirements.txt
```

**requirements.txtì— ì¶”ê°€ë˜ì–´ì•¼ í•  í•­ëª©**:
```
sqlalchemy==2.0.23
psycopg2-binary==2.9.9
alembic==1.13.1
```

---

#### Step 1.5: SQLAlchemy ëª¨ë¸ ìƒì„±

**íŒŒì¼ ìƒì„±**: `backend/database/models.py`

```python
"""
SQLAlchemy ORM ëª¨ë¸ ì •ì˜
"""
from sqlalchemy import Column, Integer, String, Float, Boolean, DateTime, Text, ForeignKey
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime

Base = declarative_base()


class MonitoredProduct(Base):
    """ëª¨ë‹ˆí„°ë§ ìƒí’ˆ"""
    __tablename__ = 'monitored_products'

    id = Column(Integer, primary_key=True, autoincrement=True)
    product_name = Column(String, nullable=False)
    product_url = Column(String, nullable=False, unique=True)
    source = Column(String, nullable=False)
    current_price = Column(Float)
    original_price = Column(Float)
    current_status = Column(String, default='available')
    check_interval = Column(Integer, default=900)
    last_checked = Column(DateTime, default=datetime.utcnow)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    notes = Column(Text)
    is_active = Column(Boolean, default=True)
    thumbnail_url = Column(String)

    # ê´€ê³„
    price_history = relationship("PriceHistory", back_populates="product")


class PriceHistory(Base):
    """ê°€ê²© ë³€ë™ ì´ë ¥"""
    __tablename__ = 'price_history'

    id = Column(Integer, primary_key=True, autoincrement=True)
    product_id = Column(Integer, ForeignKey('monitored_products.id'), nullable=False)
    price = Column(Float, nullable=False)
    status = Column(String, nullable=False)
    checked_at = Column(DateTime, default=datetime.utcnow)
    price_change = Column(Float)

    # ê´€ê³„
    product = relationship("MonitoredProduct", back_populates="price_history")


class MySellingProduct(Base):
    """ë‚´ íŒë§¤ ìƒí’ˆ"""
    __tablename__ = 'my_selling_products'

    id = Column(Integer, primary_key=True, autoincrement=True)
    product_name = Column(String, nullable=False)
    selling_price = Column(Float, nullable=False)
    monitored_product_id = Column(Integer, ForeignKey('monitored_products.id'))
    sourcing_url = Column(String)
    sourcing_product_name = Column(String)
    sourcing_price = Column(Float)
    sourcing_source = Column(String)
    detail_page_data = Column(Text)  # JSON
    category = Column(String)
    thumbnail_url = Column(String)
    original_thumbnail_url = Column(String)
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    notes = Column(Text)

    # ê´€ê³„
    monitored_product = relationship("MonitoredProduct")


# ... (ë‚˜ë¨¸ì§€ í…Œì´ë¸”ë„ ë™ì¼í•˜ê²Œ ì‘ì„±)
```

---

#### Step 1.6: Database ì—°ê²° ë ˆì´ì–´ ìƒì„±

**íŒŒì¼ ìƒì„±**: `backend/database/connection.py`

```python
"""
ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê´€ë¦¬
"""
import os
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session
from contextlib import contextmanager
from typing import Generator

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ DATABASE_URL ê°€ì ¸ì˜¤ê¸°
DATABASE_URL = os.getenv('DATABASE_URL', 'sqlite:///./monitoring.db')

# PostgreSQL URL ìˆ˜ì • (SupabaseëŠ” postgresql:// ì‚¬ìš©)
if DATABASE_URL.startswith('postgres://'):
    DATABASE_URL = DATABASE_URL.replace('postgres://', 'postgresql://', 1)

# ì—”ì§„ ìƒì„±
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,  # ì—°ê²° í™•ì¸
    pool_size=10,
    max_overflow=20,
    echo=False  # SQL ë¡œê·¸ (ë””ë²„ê¹… ì‹œ True)
)

# ì„¸ì…˜ íŒ©í† ë¦¬
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)


@contextmanager
def get_db_session() -> Generator[Session, None, None]:
    """ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ì œê³µ"""
    session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception:
        session.rollback()
        raise
    finally:
        session.close()


def get_db() -> Session:
    """FastAPI dependencyë¡œ ì‚¬ìš©"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

---

#### Step 1.7: ê¸°ì¡´ Database í´ë˜ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜

**íŒŒì¼ ìˆ˜ì •**: `backend/database/db.py`

ê¸°ì¡´ SQLite ì½”ë“œë¥¼ ìœ ì§€í•˜ë©´ì„œ SQLAlchemyë¡œ ì „í™˜:

```python
"""
ë°ì´í„°ë² ì´ìŠ¤ ë ˆì´ì–´ - SQLAlchemy ë²„ì „
"""
import os
from typing import List, Dict, Optional
from .connection import get_db_session
from .models import MonitoredProduct, PriceHistory, MySellingProduct
from sqlalchemy import func

class Database:
    """ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ í´ë˜ìŠ¤"""

    def __init__(self):
        # SQLite ëª¨ë“œ ë˜ëŠ” PostgreSQL ëª¨ë“œ ìë™ ì„ íƒ
        self.database_url = os.getenv('DATABASE_URL', 'sqlite:///./monitoring.db')
        self.use_orm = not self.database_url.startswith('sqlite://')

    # ëª¨ë‹ˆí„°ë§ ìƒí’ˆ ê´€ë ¨
    def add_monitored_product(self, product_name: str, product_url: str, source: str, **kwargs) -> int:
        """ëª¨ë‹ˆí„°ë§ ìƒí’ˆ ì¶”ê°€"""
        if self.use_orm:
            with get_db_session() as session:
                product = MonitoredProduct(
                    product_name=product_name,
                    product_url=product_url,
                    source=source,
                    **kwargs
                )
                session.add(product)
                session.flush()
                return product.id
        else:
            # ê¸°ì¡´ SQLite ì½”ë“œ ìœ ì§€
            pass

    def get_monitored_products(self, is_active: Optional[bool] = None) -> List[Dict]:
        """ëª¨ë‹ˆí„°ë§ ìƒí’ˆ ëª©ë¡ ì¡°íšŒ"""
        if self.use_orm:
            with get_db_session() as session:
                query = session.query(MonitoredProduct)
                if is_active is not None:
                    query = query.filter(MonitoredProduct.is_active == is_active)
                products = query.all()
                return [self._model_to_dict(p) for p in products]
        else:
            # ê¸°ì¡´ SQLite ì½”ë“œ ìœ ì§€
            pass

    def _model_to_dict(self, model) -> Dict:
        """SQLAlchemy ëª¨ë¸ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {c.name: getattr(model, c.name) for c in model.__table__.columns}

    # ... (ë‚˜ë¨¸ì§€ ë©”ì„œë“œë„ ë™ì¼í•˜ê²Œ ì‘ì„±)
```

**ì „ëµ**:
- ë¡œì»¬ì—ì„œëŠ” SQLite ì‚¬ìš© (`DATABASE_URL` ì—†ìŒ)
- ë°°í¬ í™˜ê²½ì—ì„œëŠ” PostgreSQL ì‚¬ìš© (`DATABASE_URL` ìˆìŒ)

---

### Day 5-7: ì´ë¯¸ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜

#### Step 1.8: Supabase Storage ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸

**íŒŒì¼ ìƒì„±**: `backend/migrate_images_to_supabase.py`

```python
"""
ë¡œì»¬ ì´ë¯¸ì§€ë¥¼ Supabase Storageë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
"""
import os
from pathlib import Path
from supabase import create_client, Client
from dotenv import load_dotenv
from tqdm import tqdm

load_dotenv('.env.local')

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
supabase: Client = create_client(
    os.getenv('SUPABASE_URL'),
    os.getenv('SUPABASE_SERVICE_ROLE_KEY')  # Service Role Key ì‚¬ìš© (ê¶Œí•œ í•„ìš”)
)

def upload_directory(local_dir: Path, bucket_name: str = 'product-images'):
    """ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ"""

    if not local_dir.exists():
        print(f"âŒ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {local_dir}")
        return

    # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp']
    image_files = []
    for ext in image_extensions:
        image_files.extend(local_dir.rglob(f'*{ext}'))

    print(f"ğŸ“‚ ì´ {len(image_files)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")

    uploaded = 0
    failed = 0

    for image_path in tqdm(image_files, desc="ì—…ë¡œë“œ ì¤‘"):
        try:
            # ìƒëŒ€ ê²½ë¡œ ê³„ì‚° (ë²„í‚· ë‚´ ê²½ë¡œ)
            relative_path = str(image_path.relative_to(local_dir))

            # íŒŒì¼ ì½ê¸°
            with open(image_path, 'rb') as f:
                file_data = f.read()

            # Supabase Storageì— ì—…ë¡œë“œ
            result = supabase.storage.from_(bucket_name).upload(
                path=relative_path,
                file=file_data,
                file_options={
                    "content-type": f"image/{image_path.suffix[1:]}",
                    "upsert": "true"  # ì´ë¯¸ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
                }
            )

            uploaded += 1

        except Exception as e:
            print(f"âŒ ì‹¤íŒ¨: {image_path.name} - {e}")
            failed += 1

    print(f"\nâœ… ì—…ë¡œë“œ ì™„ë£Œ: {uploaded}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {failed}ê°œ")

    # ì—…ë¡œë“œëœ URL ì˜ˆì‹œ ì¶œë ¥
    if uploaded > 0:
        example_url = supabase.storage.from_(bucket_name).get_public_url(relative_path)
        print(f"\nğŸ“ ì´ë¯¸ì§€ URL í˜•ì‹: {example_url}")


if __name__ == "__main__":
    print("ğŸš€ Supabase Storage ì´ë¯¸ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘\n")

    # supabase-images í´ë” ì—…ë¡œë“œ
    images_dir = Path(__file__).parent.parent / 'supabase-images'
    upload_directory(images_dir, 'product-images')

    print("\nâœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
    print("ğŸ‘‰ ì´ì œ ë¡œì»¬ ì´ë¯¸ì§€ URLì„ Supabase URLë¡œ ë³€ê²½í•˜ì„¸ìš”")
```

**ì‹¤í–‰**:
```bash
cd backend

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install supabase tqdm

# ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
python migrate_images_to_supabase.py
```

**ì˜ˆìƒ ì‹œê°„**: ì´ë¯¸ì§€ ê°œìˆ˜ì— ë”°ë¼ 5-30ë¶„

---

#### Step 1.9: ì´ë¯¸ì§€ URL ì—…ë°ì´íŠ¸

ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ë©´ DBì˜ URLì„ Supabase URLë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.

**íŒŒì¼ ìƒì„±**: `backend/update_image_urls.py`

```python
"""
DBì˜ ë¡œì»¬ ì´ë¯¸ì§€ URLì„ Supabase URLë¡œ ë³€ê²½
"""
import os
from database.db import get_db
from dotenv import load_dotenv

load_dotenv('.env.local')

SUPABASE_URL = os.getenv('SUPABASE_URL')
BUCKET_NAME = 'product-images'

def update_urls():
    """ëª¨ë“  ì´ë¯¸ì§€ URL ì—…ë°ì´íŠ¸"""
    db = get_db()

    # 1. monitored_productsì˜ thumbnail_url ì—…ë°ì´íŠ¸
    products = db.get_monitored_products()
    updated_count = 0

    for product in products:
        old_url = product.get('thumbnail_url')
        if old_url and old_url.startswith('/supabase-images/'):
            # /supabase-images/1_í°ë°¥/image.jpg â†’ 1_í°ë°¥/image.jpg
            relative_path = old_url.replace('/supabase-images/', '')

            # Supabase URLë¡œ ë³€ê²½
            new_url = f"{SUPABASE_URL}/storage/v1/object/public/{BUCKET_NAME}/{relative_path}"

            db.update_monitored_product(
                product_id=product['id'],
                thumbnail_url=new_url
            )
            updated_count += 1
            print(f"âœ… Updated: {product['product_name']}")

    print(f"\nâœ… ì´ {updated_count}ê°œ URL ì—…ë°ì´íŠ¸ ì™„ë£Œ")

if __name__ == "__main__":
    update_urls()
```

---

### Day 8-10: ë¡œì»¬ í…ŒìŠ¤íŠ¸

#### Step 1.10: ë¡œì»¬ì—ì„œ PostgreSQL í…ŒìŠ¤íŠ¸

ë¡œì»¬ì—ì„œ Dockerë¡œ PostgreSQLì„ ì‹¤í–‰í•˜ì—¬ í…ŒìŠ¤íŠ¸:

```bash
# Docker PostgreSQL ì‹¤í–‰
docker run -d \
  --name postgres-test \
  -e POSTGRES_PASSWORD=testpass \
  -e POSTGRES_DB=onbaek_test \
  -p 5432:5432 \
  postgres:15

# .env.localì— í…ŒìŠ¤íŠ¸ DATABASE_URL ì¶”ê°€
echo "DATABASE_URL=postgresql://postgres:testpass@localhost:5432/onbaek_test" >> .env.local

# ì„œë²„ ì‹¤í–‰
cd backend
python main.py
```

**í…ŒìŠ¤íŠ¸ í•­ëª©**:
- [ ] ì„œë²„ê°€ ì •ìƒ ì‹¤í–‰ë˜ëŠ”ê°€?
- [ ] API ì—”ë“œí¬ì¸íŠ¸ê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ê°€?
- [ ] ë°ì´í„° CRUDê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ê°€?
- [ ] ì´ë¯¸ì§€ê°€ Supabaseì—ì„œ ë¡œë”©ë˜ëŠ”ê°€?

**ë¬¸ì œ ë°œìƒ ì‹œ**:
- ë¡œê·¸ í™•ì¸
- SQLAlchemy echo=Trueë¡œ SQL ì¿¼ë¦¬ í™•ì¸
- ìŠ¤í‚¤ë§ˆ ë¹„êµ (SQLite vs PostgreSQL)

---

### âœ… Phase 1 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

ë‹¤ìŒ í•­ëª©ì´ ëª¨ë‘ ì²´í¬ë˜ë©´ Phase 2ë¡œ ì§„í–‰:

- [ ] Supabase í”„ë¡œì íŠ¸ ìƒì„± ì™„ë£Œ
- [ ] PostgreSQL ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ
- [ ] SQLAlchemy ëª¨ë¸ ì‘ì„± ì™„ë£Œ
- [ ] Database í´ë˜ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
- [ ] ì´ë¯¸ì§€ Supabase Storage ì—…ë¡œë“œ ì™„ë£Œ
- [ ] ì´ë¯¸ì§€ URL ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] ë¡œì»¬ì—ì„œ PostgreSQL í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸ ì •ìƒ ì‘ë™
- [ ] Git ì»¤ë°‹ ë° í‘¸ì‹œ ì™„ë£Œ

```bash
git add .
git commit -m "Phase 1 complete: Database migration to PostgreSQL"
git push
```

---

## ğŸ“… Week 3-4: Phase 2 - ë°±ì—”ë“œ ë°°í¬

### Day 11-12: Railway ì„¤ì •

#### Step 2.1: Railway í”„ë¡œì íŠ¸ ìƒì„±

1. Railway ëŒ€ì‹œë³´ë“œ ì ‘ì†: https://railway.app/dashboard
2. "New Project" í´ë¦­
3. "Deploy from GitHub repo" ì„ íƒ
4. ì €ì¥ì†Œ ì„ íƒ: `your-username/onbaek-ai`
5. í”„ë¡œì íŠ¸ ì´ë¦„: "onbaek-ai-backend"

---

#### Step 2.2: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

Railway Dashboard â†’ Variables íƒ­:

```env
# Database
DATABASE_URL=${{Postgres.DATABASE_URL}}  # Railway PostgreSQL ë˜ëŠ” Supabase

# Supabase (Supabase ì‚¬ìš© ì‹œ)
SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# OpenAI
OPENAI_API_KEY=sk-...

# Playauto
PLAYAUTO_EMAIL=your@email.com
PLAYAUTO_PASSWORD=your_password

# Slack (ì„ íƒ)
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...

# Discord (ì„ íƒ)
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/...

# Environment
ENVIRONMENT=production
PORT=8000

# Sentry (ì„ íƒ)
SENTRY_DSN=https://...@sentry.io/...
```

---

#### Step 2.3: í”„ë¡œë•ì…˜ ì„¤ì • íŒŒì¼ ìƒì„±

**íŒŒì¼ ìƒì„±**: `backend/gunicorn_conf.py`

```python
"""
Gunicorn í”„ë¡œë•ì…˜ ì„¤ì •
"""
import os
import multiprocessing

# ì„œë²„ ì†Œì¼“
bind = f"0.0.0.0:{os.getenv('PORT', '8000')}"

# Worker í”„ë¡œì„¸ìŠ¤
workers = multiprocessing.cpu_count() * 2 + 1
worker_class = "uvicorn.workers.UvicornWorker"
worker_connections = 1000
max_requests = 1000
max_requests_jitter = 50

# íƒ€ì„ì•„ì›ƒ
timeout = 120
graceful_timeout = 30
keepalive = 5

# ë¡œê¹…
accesslog = "-"
errorlog = "-"
loglevel = "info"
access_log_format = '%(h)s %(l)s %(u)s %(t)s "%(r)s" %(s)s %(b)s "%(f)s" "%(a)s" %(D)s'

# í”„ë¡œì„¸ìŠ¤ ì´ë¦„
proc_name = "onbaek-ai-backend"

# ì¬ì‹œì‘ ì •ì±…
preload_app = True
reload = False
```

---

**íŒŒì¼ ìƒì„±**: `backend/Procfile` (Railwayìš©)

```
web: gunicorn -c gunicorn_conf.py main:app
```

---

**íŒŒì¼ ìƒì„±**: `railway.json`

```json
{
  "$schema": "https://railway.app/railway.schema.json",
  "build": {
    "builder": "NIXPACKS",
    "buildCommand": "cd backend && pip install -r requirements.txt"
  },
  "deploy": {
    "startCommand": "cd backend && gunicorn -c gunicorn_conf.py main:app",
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 10,
    "healthcheckPath": "/health",
    "healthcheckTimeout": 100
  }
}
```

---

#### Step 2.4: Requirements ì—…ë°ì´íŠ¸

```bash
cd backend

# Gunicorn ì¶”ê°€
pip install gunicorn

# ì „ì²´ íŒ¨í‚¤ì§€ ëª©ë¡ ê°±ì‹ 
pip freeze > requirements.txt
```

**requirements.txt í™•ì¸**:
```
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
gunicorn>=21.2.0
sqlalchemy>=2.0.23
psycopg2-binary>=2.9.9
python-dotenv>=1.0.0
supabase>=2.0.0
```

---

#### Step 2.5: Health Check ê°•í™”

**íŒŒì¼ ìˆ˜ì •**: `backend/main.py`

```python
@app.get("/health")
async def health_check():
    """í”„ë¡œë•ì…˜ìš© í—¬ìŠ¤ ì²´í¬"""
    health_status = {
        "status": "healthy",
        "environment": os.getenv("ENVIRONMENT", "development"),
        "timestamp": datetime.now().isoformat()
    }

    # DB ì—°ê²° í™•ì¸
    try:
        db = get_db()
        # ê°„ë‹¨í•œ ì¿¼ë¦¬ ì‹¤í–‰
        products = db.get_monitored_products(limit=1)
        health_status["database"] = "ok"
    except Exception as e:
        health_status["database"] = f"error: {str(e)}"
        health_status["status"] = "unhealthy"

    # Supabase Storage í™•ì¸ (ì„ íƒ)
    try:
        if os.getenv('SUPABASE_URL'):
            from supabase import create_client
            supabase = create_client(
                os.getenv('SUPABASE_URL'),
                os.getenv('SUPABASE_ANON_KEY')
            )
            # ë²„í‚· ì¡´ì¬ í™•ì¸
            buckets = supabase.storage.list_buckets()
            health_status["storage"] = "ok"
    except Exception as e:
        health_status["storage"] = f"error: {str(e)}"

    return health_status
```

---

#### Step 2.6: Git í‘¸ì‹œ ë° ìë™ ë°°í¬

```bash
git add .
git commit -m "Add Railway production configuration"
git push
```

Railwayê°€ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ë°°í¬ ì‹œì‘.

**Railway ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸**:
- Build Logs í™•ì¸
- Deploy Logs í™•ì¸
- ë°°í¬ ì™„ë£Œ í›„ URL í™•ì¸: `https://your-app.railway.app`

**í…ŒìŠ¤íŠ¸**:
```bash
# Health check
curl https://your-app.railway.app/health

# API í…ŒìŠ¤íŠ¸
curl https://your-app.railway.app/api/products
```

---

### Day 13-14: ìŠ¤ì¼€ì¤„ëŸ¬ ë¶„ë¦¬

#### Step 2.7: Cron ì—”ë“œí¬ì¸íŠ¸ ìƒì„±

**íŒŒì¼ ìƒì„±**: `backend/api/cron.py`

```python
"""
Cron ì‘ì—…ìš© ì—”ë“œí¬ì¸íŠ¸
"""
from fastapi import APIRouter, Header, HTTPException
import os

router = APIRouter(prefix="/cron", tags=["Cron"])

# Cron ì‹œí¬ë¦¿ (Railway Variablesì— ì„¤ì •)
CRON_SECRET = os.getenv("CRON_SECRET", "change-this-secret")


def verify_cron_secret(authorization: str = Header(None)):
    """Cron ìš”ì²­ ì¸ì¦"""
    if not authorization or authorization != f"Bearer {CRON_SECRET}":
        raise HTTPException(status_code=401, detail="Unauthorized")


@router.post("/monitor-products")
async def cron_monitor_products(auth: None = Depends(verify_cron_secret)):
    """ìƒí’ˆ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰ (10ë¶„ë§ˆë‹¤)"""
    try:
        from monitor.product_monitor import check_all_products
        await check_all_products()
        return {"status": "success", "message": "Monitoring completed"}
    except Exception as e:
        return {"status": "error", "message": str(e)}


@router.post("/sync-playauto-orders")
async def cron_sync_orders(auth: None = Depends(verify_cron_secret)):
    """í”Œë ˆì´ì˜¤í†  ì£¼ë¬¸ ë™ê¸°í™” (1ì‹œê°„ë§ˆë‹¤)"""
    try:
        from playauto.scheduler import sync_orders
        await sync_orders()
        return {"status": "success", "message": "Orders synced"}
    except Exception as e:
        return {"status": "error", "message": str(e)}


@router.post("/backup-database")
async def cron_backup(auth: None = Depends(verify_cron_secret)):
    """ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… (ë§¤ì¼ ìƒˆë²½ 2ì‹œ)"""
    try:
        from backup.scheduler import create_backup
        await create_backup()
        return {"status": "success", "message": "Backup completed"}
    except Exception as e:
        return {"status": "error", "message": str(e)}
```

**main.pyì— ë¼ìš°í„° ë“±ë¡**:
```python
from api.cron import router as cron_router
app.include_router(cron_router)
```

---

#### Step 2.8: Railway Cron ì„¤ì •

**railway.jsonì— ì¶”ê°€**:
```json
{
  "deploy": {
    "cron": [
      {
        "schedule": "*/10 * * * *",
        "command": "curl -X POST https://your-app.railway.app/cron/monitor-products -H 'Authorization: Bearer ${CRON_SECRET}'"
      },
      {
        "schedule": "0 * * * *",
        "command": "curl -X POST https://your-app.railway.app/cron/sync-playauto-orders -H 'Authorization: Bearer ${CRON_SECRET}'"
      },
      {
        "schedule": "0 2 * * *",
        "command": "curl -X POST https://your-app.railway.app/cron/backup-database -H 'Authorization: Bearer ${CRON_SECRET}'"
      }
    ]
  }
}
```

**í™˜ê²½ ë³€ìˆ˜ ì¶”ê°€** (Railway Dashboard):
```
CRON_SECRET=your-random-secret-key-here
```

---

### âœ… Phase 2 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Railway í”„ë¡œì íŠ¸ ìƒì„±
- [ ] í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ
- [ ] Gunicorn ì„¤ì • ì™„ë£Œ
- [ ] ìë™ ë°°í¬ ì„±ê³µ
- [ ] Health check API ì •ìƒ
- [ ] ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸ ë™ì‘
- [ ] Cron ì—”ë“œí¬ì¸íŠ¸ ìƒì„±
- [ ] Railway Cron ì„¤ì • ì™„ë£Œ
- [ ] ìŠ¤ì¼€ì¤„ëŸ¬ ì •ìƒ ë™ì‘ í™•ì¸

**ë°±ì—”ë“œ URL ê¸°ë¡**:
```
https://your-app.railway.app
```

---

## ğŸ“… Week 5: Phase 3 - í”„ë¡ íŠ¸ì—”ë“œ ë°°í¬

### Day 15-16: Vercel ë°°í¬

#### Step 3.1: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

**íŒŒì¼ ìƒì„±**: `.env.production`

```env
NEXT_PUBLIC_API_URL=https://your-app.railway.app
```

---

#### Step 3.2: Next.js ì„¤ì • ìˆ˜ì •

**íŒŒì¼ ìˆ˜ì •**: `next.config.js`

```javascript
/** @type {import('next').NextConfig} */
const nextConfig = {
  images: {
    domains: [
      'xxxxx.supabase.co',  // Supabase Storage
      'localhost',
    ],
    formats: ['image/avif', 'image/webp'],
  },
  // í™˜ê²½ ë³€ìˆ˜ ë…¸ì¶œ
  env: {
    NEXT_PUBLIC_API_URL: process.env.NEXT_PUBLIC_API_URL,
  },
}

module.exports = nextConfig
```

---

#### Step 3.3: API URL ìˆ˜ì •

í”„ë¡ íŠ¸ì—”ë“œ ì½”ë“œì—ì„œ API URLì„ í™˜ê²½ ë³€ìˆ˜ë¡œ ë³€ê²½:

**ì „ì—­ ê²€ìƒ‰ ë° ìˆ˜ì •**:
```typescript
// ê¸°ì¡´
const API_BASE_URL = 'http://localhost:8000';

// ë³€ê²½
const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000';
```

**íŒŒì¼ ìˆ˜ì • í•„ìš”**:
- `components/pages/ProductSourcingPage.tsx`
- `components/pages/DetailPage.tsx`
- `components/pages/UnifiedOrderManagementPage.tsx`
- ê¸°íƒ€ API í˜¸ì¶œí•˜ëŠ” ëª¨ë“  íŒŒì¼

---

#### Step 3.4: Vercel í”„ë¡œì íŠ¸ ìƒì„±

1. Vercel ëŒ€ì‹œë³´ë“œ: https://vercel.com/dashboard
2. "Add New" â†’ "Project"
3. GitHub ì €ì¥ì†Œ ì„ íƒ: `your-username/onbaek-ai`
4. Framework Preset: **Next.js** (ìë™ ê°ì§€)
5. Root Directory: `.` (í”„ë¡œì íŠ¸ ë£¨íŠ¸)
6. Build Command: `npm run build`
7. Output Directory: `.next`

---

#### Step 3.5: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

Vercel Dashboard â†’ Settings â†’ Environment Variables:

```
NEXT_PUBLIC_API_URL=https://your-app.railway.app
```

**ëª¨ë“  í™˜ê²½ì— ì ìš©**: Production, Preview, Development

---

#### Step 3.6: ë°°í¬

1. "Deploy" ë²„íŠ¼ í´ë¦­
2. ìë™ ë¹Œë“œ ì‹œì‘
3. ë°°í¬ ì™„ë£Œ í›„ URL í™•ì¸: `https://your-domain.vercel.app`

**í…ŒìŠ¤íŠ¸**:
- í”„ë¡ íŠ¸ì—”ë“œ ì ‘ì†
- ìƒí’ˆ ëª©ë¡ ë¡œë”© í™•ì¸
- API ì—°ê²° í™•ì¸
- ì´ë¯¸ì§€ ë¡œë”© í™•ì¸

---

#### Step 3.7: ì»¤ìŠ¤í…€ ë„ë©”ì¸ (ì„ íƒ)

1. Vercel Dashboard â†’ Settings â†’ Domains
2. ë„ë©”ì¸ ì…ë ¥: `yourdomain.com`
3. DNS ë ˆì½”ë“œ ì¶”ê°€ (ë„ë©”ì¸ ì œê³µì—…ì²´ì—ì„œ):
   ```
   A    @    76.76.21.21
   CNAME www  cname.vercel-dns.com
   ```
4. ìë™ HTTPS ì„¤ì • (Let's Encrypt)

---

### Day 17: CORS ì—…ë°ì´íŠ¸

#### Step 3.8: ë°±ì—”ë“œ CORS ì„¤ì •

**íŒŒì¼ ìˆ˜ì •**: `backend/main.py`

```python
# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",  # ë¡œì»¬ ê°œë°œ
        "https://your-domain.vercel.app",  # Vercel ë°°í¬
        "https://yourdomain.com",  # ì»¤ìŠ¤í…€ ë„ë©”ì¸ (ìˆëŠ” ê²½ìš°)
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"],
    allow_headers=["*"],
)
```

**Git í‘¸ì‹œ**:
```bash
git add .
git commit -m "Update CORS for production"
git push
```

Railwayê°€ ìë™ìœ¼ë¡œ ì¬ë°°í¬.

---

### âœ… Phase 3 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Next.js í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
- [ ] API URL ëª¨ë‘ ìˆ˜ì •
- [ ] Vercel í”„ë¡œì íŠ¸ ìƒì„±
- [ ] ìë™ ë°°í¬ ì„±ê³µ
- [ ] í”„ë¡ íŠ¸ì—”ë“œ ì •ìƒ ì ‘ì†
- [ ] API ì—°ê²° í™•ì¸
- [ ] ì´ë¯¸ì§€ ë¡œë”© í™•ì¸
- [ ] CORS ì„¤ì • ì™„ë£Œ
- [ ] (ì„ íƒ) ì»¤ìŠ¤í…€ ë„ë©”ì¸ ì—°ê²°

**í”„ë¡ íŠ¸ì—”ë“œ URL ê¸°ë¡**:
```
https://your-domain.vercel.app
```

---

## ğŸ“… Week 6: Phase 4 - í†µí•© í…ŒìŠ¤íŠ¸ & ë³´ì•ˆ

### Day 18-19: E2E í…ŒìŠ¤íŠ¸

#### Step 4.1: ì „ì²´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

ë‹¤ìŒ ê¸°ëŠ¥ë“¤ì„ ì‹¤ì œë¡œ í…ŒìŠ¤íŠ¸:

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ìƒí’ˆ ëª¨ë‹ˆí„°ë§ ë“±ë¡
- [ ] ê°€ê²© ë³€ë™ í™•ì¸
- [ ] AI ìƒì„¸í˜ì´ì§€ ìƒì„±
- [ ] í”Œë ˆì´ì˜¤í†  ì£¼ë¬¸ ë™ê¸°í™”
- [ ] ì†¡ì¥ ì—…ë¡œë“œ
- [ ] Slack/Discord ì•Œë¦¼
- [ ] Excel ë‚´ë³´ë‚´ê¸°
- [ ] ëª¨ë“  í˜ì´ì§€ ì ‘ê·¼

**ë²„ê·¸ ë°œê²¬ ì‹œ**:
- ë¡œê·¸ í™•ì¸ (Railway Dashboard â†’ Logs)
- Sentryì—ì„œ ì—ëŸ¬ í™•ì¸
- ìˆ˜ì • í›„ ì¬ë°°í¬

---

### Day 20-21: ëª¨ë‹ˆí„°ë§ ì„¤ì •

#### Step 4.2: Sentry ì„¤ì •

**ë°±ì—”ë“œ Sentry**:

```bash
cd backend
pip install sentry-sdk
```

**main.pyì— ì¶”ê°€**:
```python
import sentry_sdk

if os.getenv("SENTRY_DSN"):
    sentry_sdk.init(
        dsn=os.getenv("SENTRY_DSN"),
        traces_sample_rate=0.1,
        environment=os.getenv("ENVIRONMENT", "production"),
    )
```

**í”„ë¡ íŠ¸ì—”ë“œ Sentry**:

```bash
npm install @sentry/nextjs
npx @sentry/wizard -i nextjs
```

---

#### Step 4.3: Uptime ëª¨ë‹ˆí„°ë§

1. UptimeRobot ê°€ì…: https://uptimerobot.com/
2. ìƒˆ ëª¨ë‹ˆí„° ìƒì„±:
   - Monitor Type: HTTP(s)
   - URL: `https://your-app.railway.app/health`
   - Monitoring Interval: 5 minutes
3. Alert Contacts ì„¤ì • (ì´ë©”ì¼, Slack)

---

### Day 22: ë³´ì•ˆ ê°•í™”

#### Step 4.4: Rate Limiting

```bash
cd backend
pip install slowapi
```

**main.pyì— ì¶”ê°€**:
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# APIì— ì ìš©
@router.post("/generate-content")
@limiter.limit("10/minute")  # 1ë¶„ì— 10íšŒë§Œ
async def generate_content(request: Request):
    ...
```

---

### âœ… Phase 4 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ì „ì²´ ê¸°ëŠ¥ E2E í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] Sentry ì„¤ì • ì™„ë£Œ
- [ ] Uptime ëª¨ë‹ˆí„°ë§ ì„¤ì •
- [ ] Rate Limiting ì ìš©
- [ ] ë³´ì•ˆ ì·¨ì•½ì  í™•ì¸
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ

---

## ğŸ“… Week 7+: Phase 5 - ìµœì í™” (ì§€ì†)

### ì§€ì†ì  ê°œì„  ì‘ì—…

#### Step 5.1: Redis ìºì‹± (ì„ íƒ)

íŠ¸ë˜í”½ì´ ì¦ê°€í•˜ë©´ Redis ìºì‹± ì¶”ê°€:

1. Railwayì—ì„œ Redis ì¶”ê°€
2. ìºì‹± ë ˆì´ì–´ êµ¬í˜„
3. ìì£¼ ì¡°íšŒë˜ëŠ” ë°ì´í„° ìºì‹±

---

#### Step 5.2: CI/CD íŒŒì´í”„ë¼ì¸

**íŒŒì¼ ìƒì„±**: `.github/workflows/deploy.yml`

```yaml
name: Deploy

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
      - name: Run tests
        run: |
          cd backend
          pytest

  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to Railway
        run: echo "Railway auto-deploys on push"
      - name: Deploy to Vercel
        run: echo "Vercel auto-deploys on push"
```

---

### âœ… Phase 5 ì™„ë£Œ

Phase 5ëŠ” ì§€ì†ì ì¸ ê°œì„ ì´ë¯€ë¡œ, ë‹¤ìŒ í•­ëª©ë“¤ì„ ì ì§„ì ìœ¼ë¡œ ì§„í–‰:

- [ ] Redis ìºì‹± êµ¬í˜„
- [ ] DB ì¿¼ë¦¬ ìµœì í™”
- [ ] í”„ë¡ íŠ¸ì—”ë“œ ì½”ë“œ ìŠ¤í”Œë¦¬íŒ…
- [ ] ì´ë¯¸ì§€ ìµœì í™” (WebP)
- [ ] CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- [ ] ë°±ì—… ìë™í™”
- [ ] ë¡œê·¸ ë¶„ì„

---

## ğŸ‰ ë°°í¬ ì™„ë£Œ!

ëª¨ë“  Phaseê°€ ì™„ë£Œë˜ë©´:

âœ… 24/7 ì ‘ê·¼ ê°€ëŠ¥
âœ… ìë™ ë°±ì—… & ë³µêµ¬
âœ… 99.9% ê°€ë™ë¥ 
âœ… íŒ€ í˜‘ì—… ê°€ëŠ¥
âœ… ë¹„ì¦ˆë‹ˆìŠ¤ í™•ì¥ ì¤€ë¹„ ì™„ë£Œ

**ë‹¤ìŒ ë‹¨ê³„**:
1. ì‹¤ì œ ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘
2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
3. ê¸°ëŠ¥ ê°œì„ 
4. ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥

---

## ğŸ“ ë„ì›€ì´ í•„ìš”í•˜ë©´

- DEPLOYMENT_ROADMAP.md - ìƒì„¸ ê¸°ìˆ  ë¬¸ì„œ
- DEPLOYMENT_BENEFITS.md - ë°°í¬ ì´ì 
- ê° Phaseë³„ë¡œ ë¬¸ì œ ë°œìƒ ì‹œ ì§ˆë¬¸í•˜ì„¸ìš”!
